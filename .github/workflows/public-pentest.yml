name: Run LLM Pentest & Model Scan

on:
  workflow_call:
    inputs:
      python-version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      
      # ---------- Execution toggles ----------
      enable-llm-pentest:
        description: 'Enable LLM endpoint pentesting'
        required: false
        type: boolean
        default: true
      enable-model-scanning:
        description: 'Enable model scanning'
        required: false
        type: boolean
        default: false
      
      # ---------- Inventory scope ----------
      inventory-scope:
        description: 'Inventory scope: organization|project|resource'
        required: false
        type: string
        default: 'organization'
      project-ids:
        description: 'Comma-separated project IDs (for project scope)'
        required: false
        type: string
        default: ''
      target-resource-ids:
        description: 'Comma-separated resource IDs (for resource scope)'
        required: false
        type: string
        default: ''
      target-resource-names:
        description: 'Comma-separated resource names (for resource scope)'
        required: false
        type: string
        default: ''
      
      # ---------- LLM Pentest parameters ----------
      pentest-template:
        description: 'Pentest template name to use'
        required: false
        type: string
        default: 'CI/CD Pentest All Categories'
      has-valid-pentest-connection-details:
        description: 'Filter LLM endpoints by valid pentest connection details'
        required: false
        type: boolean
        default: true
      
      # ---------- Model scanning parameters ----------
      model-scan-policies:
        description: 'Comma-separated model scan policies (empty = all)'
        required: false
        type: string
        default: ''
      model-scan-description:
        description: 'Description for model scans'
        required: false
        type: string
        default: 'CI Model Scan'
      
      # ---------- Failure thresholds ----------
      fail-outcome-at-or-above:
        description: 'Fail on outcomes at/above this level: critical|poor|moderate|good'
        required: false
        type: string
        default: 'moderate'
      on-threshold-action:
        description: 'Action on threshold breach: fail|issue|both|none'
        required: false
        type: string
        default: 'fail'
      on-hard-failures-action:
        description: 'Action on hard failures: fail|issue|both|ignore'
        required: false
        type: string
        default: 'ignore'
      
      # ---------- GitHub Issues integration ----------
      github-default-labels:
        description: 'Comma-separated default labels for GitHub issues'
        required: false
        type: string
        default: ''
      github-assignees:
        description: 'Comma-separated GitHub usernames to assign issues'
        required: false
        type: string
        default: ''
      category-issue-min-severity:
        description: 'Minimum severity for per-category issues: CRITICAL|HIGH|MEDIUM|LOW|INFORMATIONAL'
        required: false
        type: string
        default: 'INFORMATIONAL'
      
      # ---------- Concurrency & polling ----------
      max-concurrent-pentests:
        description: 'Maximum number of pentests/scans to run in parallel'
        type: number
        default: 8
      start-stagger-secs:
        description: 'Seconds to stagger between start requests'
        type: number
        default: 0
      max-start-retries:
        description: 'Retries when starting a pentest fails (retryable)'
        type: number
        default: 3
      start-retry-delay:
        description: 'Seconds to wait between start retries'
        type: number
        default: 30
      poll-timeout-secs:
        type: number
        default: 3600
      poll-timeout-action:
        description: 'What to do on poll timeout: fail|continue|partial'
        type: string
        default: 'fail'
      graphql-extended-timeout-secs:
        description: 'Extra seconds for extended GraphQL polling after RUNNING timeouts'
        type: number
        default: 1800
      graphql-poll-interval-secs:
        description: 'Interval (secs) between extended GraphQL polls'
        type: number
        default: 120
      
      # ---------- Misc ----------
      artifact-retention-days:
        description: 'Days to retain artifacts'
        required: false
        type: number
        default: 30
      log-jwt-threads:
        type: boolean
        default: false
      source-ref:
        description: 'Ref of musical-dollop to checkout (e.g., main)'
        type: string
        default: 'main'
    
    secrets:
      ALLTRUE_API_KEY:
        required: true
      ALLTRUE_API_URL:
        required: true
      ALLTRUE_CUSTOMER_ID:
        required: true
      ALLTRUE_ORGANIZATION_ID:
        required: false
      GITHUB_TOKEN:
        required: false

    outputs:
      pentest-status:
        value: ${{ jobs.run-security-scan.outputs.status }}
      worst-outcome:
        value: ${{ jobs.run-security-scan.outputs.outcome }}

jobs:
  run-security-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    outputs:
      status: ${{ steps.decide.outputs.status }}
      outcome: ${{ steps.extract-outcome.outputs.outcome }}

    steps:
      - name: Checkout musical-dollop
        uses: actions/checkout@v4
        with:
          repository: tonyAllTrue/musical-dollop
          ref: ${{ inputs.source-ref }}
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python-version }}

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run security scan script
        id: scan
        continue-on-error: true
        env:
          API_KEY: ${{ secrets.ALLTRUE_API_KEY }}
          API_URL: ${{ secrets.ALLTRUE_API_URL }}
          CUSTOMER_ID: ${{ secrets.ALLTRUE_CUSTOMER_ID }}
          ORGANIZATION_ID: ${{ secrets.ALLTRUE_ORGANIZATION_ID }}
          
          # Execution toggles
          ENABLE_LLM_PENTEST: ${{ inputs.enable-llm-pentest }}
          ENABLE_MODEL_SCANNING: ${{ inputs.enable-model-scanning }}
          
          # Inventory
          INVENTORY_SCOPE: ${{ inputs.inventory-scope }}
          PROJECT_IDS: ${{ inputs.project-ids }}
          TARGET_RESOURCE_IDS: ${{ inputs.target-resource-ids }}
          TARGET_RESOURCE_NAMES: ${{ inputs.target-resource-names }}
          
          # LLM Pentest
          TARGET_TEMPLATE_NAME: ${{ inputs.pentest-template }}
          HAS_VALID_PENTEST_CONNECTION_DETAILS: ${{ inputs.has-valid-pentest-connection-details }}
          
          # Model Scanning
          MODEL_SCAN_POLICIES: ${{ inputs.model-scan-policies }}
          MODEL_SCAN_DESCRIPTION: ${{ inputs.model-scan-description }}
          
          # Failure thresholds
          FAIL_OUTCOME_AT_OR_ABOVE: ${{ inputs.fail-outcome-at-or-above }}
          ON_THRESHOLD_ACTION: ${{ inputs.on-threshold-action }}
          ON_HARD_FAILURES_ACTION: ${{ inputs.on-hard-failures-action }}
          
          # GitHub Issues
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_DEFAULT_LABELS: ${{ inputs.github-default-labels }}
          GITHUB_ASSIGNEES: ${{ inputs.github-assignees }}
          CATEGORY_ISSUE_MIN_SEVERITY: ${{ inputs.category-issue-min-severity }}
          
          # Concurrency & Polling
          MAX_CONCURRENT_PENTESTS: ${{ inputs.max-concurrent-pentests }}
          START_STAGGER_SECS: ${{ inputs.start-stagger-secs }}
          MAX_START_RETRIES: ${{ inputs.max-start-retries }}
          START_RETRY_DELAY: ${{ inputs.start-retry-delay }}
          POLL_TIMEOUT_SECS: ${{ inputs.poll-timeout-secs }}
          POLL_TIMEOUT_ACTION: ${{ inputs.poll-timeout-action }}
          GRAPHQL_EXTENDED_TIMEOUT_SECS: ${{ inputs.graphql-extended-timeout-secs }}
          GRAPHQL_POLL_INTERVAL_SECS: ${{ inputs.graphql-poll-interval-secs }}
          
          # Misc
          LOG_JWT_THREADS: ${{ inputs.log-jwt-threads }}
        run: python run_pentest.py

      - name: Extract outcome for output
        id: extract-outcome
        if: always()
        shell: bash
        run: |
          OUTCOME="Unknown"
          
          # Check pentest results
          if [ -f "pentest_results_summary.json" ]; then
            PENTEST_OUTCOME=$(python -c "import json,sys; d=json.load(open('pentest_results_summary.json')); o=[r.get('outcome') for r in d if r.get('outcome')]; print('Critical' if ('Critical' in o or 'Poor' in o) else ('Moderate' if 'Moderate' in o else ('Good' if 'Good' in o else ('Excellent' if 'Excellent' in o else 'Unknown'))))" 2>/dev/null || echo "Unknown")
            echo "Pentest worst outcome: $PENTEST_OUTCOME"
          fi
          
          # Check model scan results
          if [ -f "model_scan_results_summary.json" ]; then
            MODEL_OUTCOME=$(python -c "import json,sys; d=json.load(open('model_scan_results_summary.json')); o=[r.get('outcome') for r in d if r.get('outcome')]; print('Critical' if ('Critical' in o or 'Poor' in o) else ('Moderate' if 'Moderate' in o else ('Good' if 'Good' in o else ('Excellent' if 'Excellent' in o else 'Unknown'))))" 2>/dev/null || echo "Unknown")
            echo "Model scan worst outcome: $MODEL_OUTCOME"
          fi
          
          # Determine overall worst outcome
          if [ -f "pentest_results_summary.json" ] && [ -f "model_scan_results_summary.json" ]; then
            # Both exist - take worse of the two
            if [ "$PENTEST_OUTCOME" = "Critical" ] || [ "$MODEL_OUTCOME" = "Critical" ]; then
              OUTCOME="Critical"
            elif [ "$PENTEST_OUTCOME" = "Poor" ] || [ "$MODEL_OUTCOME" = "Poor" ]; then
              OUTCOME="Poor"
            elif [ "$PENTEST_OUTCOME" = "Moderate" ] || [ "$MODEL_OUTCOME" = "Moderate" ]; then
              OUTCOME="Moderate"
            elif [ "$PENTEST_OUTCOME" = "Good" ] || [ "$MODEL_OUTCOME" = "Good" ]; then
              OUTCOME="Good"
            elif [ "$PENTEST_OUTCOME" = "Excellent" ] || [ "$MODEL_OUTCOME" = "Excellent" ]; then
              OUTCOME="Excellent"
            fi
          elif [ -f "pentest_results_summary.json" ]; then
            OUTCOME="$PENTEST_OUTCOME"
          elif [ -f "model_scan_results_summary.json" ]; then
            OUTCOME="$MODEL_OUTCOME"
          fi
          
          echo "Extracted worst outcome: $OUTCOME"
          echo "outcome=$OUTCOME" >> "$GITHUB_OUTPUT"

      - name: Decide workflow status
        id: decide
        if: always()
        shell: bash
        run: |
          STATUS="${{ steps.scan.outcome }}"
          WORST="${{ steps.extract-outcome.outputs.outcome }}"
          THRESHOLD="${{ inputs.fail-outcome-at-or-above }}"
          WORST="${WORST:-Unknown}"
          
          # If script succeeded, pass
          if [ "$STATUS" = "success" ]; then
            echo "status=success" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          # Script failed - determine if it's a real failure or acceptable
          # Map threshold to severity order: critical=0, poor=1, moderate=2, good=3, excellent=4
          get_severity_index() {
            case "${1,,}" in
              critical) echo 0 ;;
              poor) echo 1 ;;
              moderate) echo 2 ;;
              good) echo 3 ;;
              excellent) echo 4 ;;
              unknown) echo 999 ;;
              *) echo 999 ;;
            esac
          }
          
          WORST_IDX=$(get_severity_index "$WORST")
          THRESHOLD_IDX=$(get_severity_index "$THRESHOLD")
          
          echo "Worst outcome: $WORST (index: $WORST_IDX)"
          echo "Threshold: $THRESHOLD (index: $THRESHOLD_IDX)"
          
          # If worst is at or above threshold (lower index = more severe), fail
          if [ "$WORST_IDX" -le "$THRESHOLD_IDX" ] && [ "$WORST_IDX" -ne 999 ]; then
            echo "status=failure" >> "$GITHUB_OUTPUT"
          else
            echo "status=neutral" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload with timestamp
        if: always()
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          echo "timestamp=$TIMESTAMP" >> "$GITHUB_ENV"

      - name: Upload pentest CSV results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pentest-csv-results-${{ env.timestamp }}
          path: pentest_results_*.csv
          if-no-files-found: ignore
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Upload pentest summary JSON
        if: always() && hashFiles('pentest_results_summary.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: pentest-summary-${{ env.timestamp }}
          path: pentest_results_summary.json
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Upload model scan summary JSON
        if: always() && hashFiles('model_scan_results_summary.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: model-scan-summary-${{ env.timestamp }}
          path: model_scan_results_summary.json
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Check scan outcome and fail workflow if needed
        if: always()
        run: |
          if [ "${{ steps.decide.outputs.status }}" = "failure" ]; then
            echo "Security scan failed with severe outcome (or hard failure)."
            exit 1
          elif [ "${{ steps.decide.outputs.status }}" = "neutral" ]; then
            echo "Security scan finished with neutral status."
            exit 0
          else
            echo "Security scan completed successfully."
          fi
