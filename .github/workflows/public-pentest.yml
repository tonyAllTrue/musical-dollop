name: Run LLM Pentest & Model Scan

on:
  workflow_call:
    inputs:
      python-version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      
      # ---------- Execution toggles ----------
      enable-llm-pentest:
        description: 'Enable LLM endpoint pentesting'
        required: false
        type: boolean
        default: true
      enable-model-scanning:
        description: 'Enable model scanning'
        required: false
        type: boolean
        default: false
      
      # ---------- Inventory scope ----------
      inventory-scope:
        description: 'Inventory scope: organization|project|resource'
        required: false
        type: string
        default: 'organization'
      project-ids:
        description: 'Comma-separated project IDs (for project scope)'
        required: false
        type: string
        default: ''
      project-names:
        description: 'Comma-separated project names (will be resolved to IDs at runtime)'
        required: false
        type: string
        default: ''
      target-resource-ids:
        description: 'Comma-separated resource IDs (for resource scope)'
        required: false
        type: string
        default: ''
      target-resource-names:
        description: 'Comma-separated resource names (for resource scope)'
        required: false
        type: string
        default: ''
      
      # ---------- LLM Pentest parameters ----------
      pentest-template:
        description: 'Pentest template name to use'
        required: false
        type: string
        default: 'Prompt Injection'
      # --- Advanced Pentest Controls ---
      pentest-num-attempts:
        description: 'Number of attempts per test case to account for LLM response variability (1-5 recommended)'
        required: false
        type: string
        default: '1'
      pentest-model-mapping:
        description: "Map resource types to models, e.g. OpenAIEndpoint:gpt-4,AnthropicEndpoint:claude-3-5-sonnet-latest"
        type: string
        required: false
        default: ""
      pentest-apply-guardrails:
        description: "Apply guardrails during pentest execution"
        type: boolean
        required: false
        default: false
      pentest-system-prompt-enabled:
        description: "Enable configuring a system prompt on the endpoint before testing"
        type: boolean
        required: false
        default: false
      pentest-system-prompt-text:
        description: "System prompt text to configure on the endpoint before testing"
        type: string
        required: false
        default: ""
      pentest-cleanup-system-prompt:
        description: "Clear the configured system prompt from the endpoint after testing"
        type: boolean
        required: false
        default: true
      pentest-dataset-enabled:
        description: "Enable dataset configuration for capture-replay pentesting"
        type: boolean
        required: false
        default: false
      pentest-dataset-id:
        description: "Dataset UUID for capture-replay pentesting"
        type: string
        required: false
        default: ""
      pentest-dataset-name:
        description: "Dataset name for capture-replay pentesting (will be resolved to UUID)"
        type: string
        required: false
        default: ""
      pentest-cleanup-dataset:
        description: "Clear the configured dataset from the endpoint after testing"
        type: boolean
        required: false
        default: true
      
      # ---------- Model scanning parameters ----------
      model-scan-policies:
        description: 'Comma-separated model scan policies (empty = all)'
        required: false
        type: string
        default: 'model-scan-code-execution-prohibited,model-scan-input-output-operations-prohibited,model-scan-network-access-prohibited,model-scan-malware-signatures-prohibited,model-custom-layers-prohibited'
      model-scan-description:
        description: 'Description for model scans'
        required: false
        type: string
        default: 'CI Model Scan'
      
      # ---------- HuggingFace Model Onboarding ----------
      huggingface-onboarding-enabled:
        description: 'Enable HuggingFace model onboarding before scanning'
        required: false
        type: boolean
        default: false
      huggingface-models-to-onboard:
        description: 'HuggingFace models to onboard (format: org1/repo1,org2/repo2@revision or JSON)'
        required: false
        type: string
        default: ''
      huggingface-onboarding-project-id:
        description: 'Project ID to associate onboarded models with (uses first PROJECT_IDS if not specified)'
        required: false
        type: string
        default: ''
      huggingface-onboarding-wait-secs:
        description: 'Wait time after onboarding before scanning (seconds)'
        required: false
        type: number
        default: 10
      huggingface-onboarding-only:
        description: 'Skip inventory selection and only scan onboarded HuggingFace models'
        required: false
        type: boolean
        default: false
      
      # ---------- Failure thresholds ----------
      fail-outcome-at-or-above:
        description: 'Fail on outcomes at/above this level: critical|poor|moderate|good'
        required: false
        type: string
        default: 'moderate'
      on-threshold-action:
        description: 'Action on threshold breach: fail|issue|both|none'
        required: false
        type: string
        default: 'fail'
      on-hard-failures-action:
        description: 'Action on hard failures: fail|issue|both|ignore'
        required: false
        type: string
        default: 'ignore'
      
      # ---------- GitHub Issues integration ----------
      github-repository:
        description: 'Target GitHub repository for issues (owner/repo)'
        required: false
        type: string
        default: ''
      github-default-labels:
        description: 'Comma-separated default labels for GitHub issues'
        required: false
        type: string
        default: ''
      github-assignees:
        description: 'Comma-separated GitHub usernames to assign issues'
        required: false
        type: string
        default: ''
      category-issue-min-severity:
        description: 'Minimum severity for per-category issues: CRITICAL|HIGH|MEDIUM|LOW|INFORMATIONAL'
        required: false
        type: string
        default: 'INFORMATIONAL'
      
      # ---------- Concurrency & polling ----------
      max-concurrent-pentests:
        description: 'Maximum number of pentests/scans to run in parallel'
        type: number
        default: 8
      start-stagger-secs:
        description: 'Seconds to stagger between start requests'
        type: number
        default: 0
      max-start-retries:
        description: 'Retries when starting a pentest fails (retryable)'
        type: number
        default: 3
      start-retry-delay:
        description: 'Seconds to wait between start retries'
        type: number
        default: 30
      poll-timeout-secs:
        type: number
        default: 5400
      poll-timeout-action:
        description: 'What to do on poll timeout: fail|continue|partial'
        type: string
        default: 'fail'
      graphql-poll-interval-secs:
        description: 'Interval (secs) between GraphQL polls for execution completion'
        type: number
        default: 30
      
      # ---------- Misc ----------
      artifact-retention-days:
        description: 'Days to retain artifacts'
        required: false
        type: number
        default: 30
      source-ref:
        description: 'Ref of musical-dollop to checkout (e.g., main)'
        type: string
        default: 'main'
    
    secrets:
      ALLTRUE_API_KEY:
        required: true
      ALLTRUE_API_URL:
        required: true
      ALLTRUE_CUSTOMER_ID:
        required: true
      ALLTRUE_ORGANIZATION_ID:
        required: false
      ALLTRUE_ORGANIZATION_NAME:
        required: false
      GH_TOKEN:
        required: false

    outputs:
      pentest-status:
        value: ${{ jobs.run-security-scan.outputs.status }}
      worst-outcome:
        value: ${{ jobs.run-security-scan.outputs.outcome }}

jobs:
  run-security-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    outputs:
      status: ${{ steps.decide.outputs.status }}
      outcome: ${{ steps.extract-outcome.outputs.outcome }}

    steps:
      - name: Checkout musical-dollop
        uses: actions/checkout@v4
        with:
          repository: tonyAllTrue/musical-dollop
          ref: ${{ inputs.source-ref }}
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python-version }}

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run security scan script
        id: scan
        continue-on-error: true
        env:
          API_KEY: ${{ secrets.ALLTRUE_API_KEY }}
          API_URL: ${{ secrets.ALLTRUE_API_URL }}
          CUSTOMER_ID: ${{ secrets.ALLTRUE_CUSTOMER_ID }}
          ORGANIZATION_ID: ${{ secrets.ALLTRUE_ORGANIZATION_ID }}
          ORGANIZATION_NAME: ${{ secrets.ALLTRUE_ORGANIZATION_NAME }}
          
          # Execution toggles
          ENABLE_LLM_PENTEST: ${{ inputs.enable-llm-pentest }}
          ENABLE_MODEL_SCANNING: ${{ inputs.enable-model-scanning }}
          
          # Inventory
          INVENTORY_SCOPE: ${{ inputs.inventory-scope }}
          PROJECT_IDS: ${{ inputs.project-ids }}
          PROJECT_NAMES: ${{ inputs.project-names }}
          TARGET_RESOURCE_IDS: ${{ inputs.target-resource-ids }}
          TARGET_RESOURCE_NAMES: ${{ inputs.target-resource-names }}
          
          # LLM Pentest
          TARGET_TEMPLATE_NAME: ${{ inputs.pentest-template }}
          # --- Advanced Pentest Controls  ---
          PENTEST_NUM_ATTEMPTS: ${{ inputs.pentest-num-attempts }}
          # Model selection by resource type
          PENTEST_MODEL_MAPPING: ${{ inputs.pentest-model-mapping }}
          # Guardrails on/off
          PENTEST_APPLY_GUARDRAILS: ${{ inputs.pentest-apply-guardrails }}
          # System prompt plumbing
          PENTEST_SYSTEM_PROMPT_ENABLED: ${{ inputs.pentest-system-prompt-enabled }}
          PENTEST_SYSTEM_PROMPT_TEXT: ${{ inputs.pentest-system-prompt-text }}
          PENTEST_CLEANUP_SYSTEM_PROMPT: ${{ inputs.pentest-cleanup-system-prompt }}
          # Dataset configuration for capture-replay
          PENTEST_DATASET_ENABLED: ${{ inputs.pentest-dataset-enabled }}
          PENTEST_DATASET_ID: ${{ inputs.pentest-dataset-id }}
          PENTEST_DATASET_NAME: ${{ inputs.pentest-dataset-name }}
          PENTEST_CLEANUP_DATASET: ${{ inputs.pentest-cleanup-dataset }}
          
          # Model Scanning
          MODEL_SCAN_POLICIES: ${{ inputs.model-scan-policies }}
          MODEL_SCAN_DESCRIPTION: ${{ inputs.model-scan-description }}
          # HuggingFace Model Onboarding
          HUGGINGFACE_ONBOARDING_ENABLED: ${{ inputs.huggingface-onboarding-enabled }}
          HUGGINGFACE_MODELS_TO_ONBOARD: ${{ inputs.huggingface-models-to-onboard }}
          HUGGINGFACE_ONBOARDING_PROJECT_ID: ${{ inputs.huggingface-onboarding-project-id }}
          HUGGINGFACE_ONBOARDING_WAIT_SECS: ${{ inputs.huggingface-onboarding-wait-secs }}
          HUGGINGFACE_ONBOARDING_ONLY: ${{ inputs.huggingface-onboarding-only }}
          
          
          # Failure thresholds
          FAIL_OUTCOME_AT_OR_ABOVE: ${{ inputs.fail-outcome-at-or-above }}
          ON_THRESHOLD_ACTION: ${{ inputs.on-threshold-action }}
          ON_HARD_FAILURES_ACTION: ${{ inputs.on-hard-failures-action }}
          
          # GitHub Issues
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
          GITHUB_REPOSITORY: ${{ inputs.github-repository != '' && inputs.github-repository || github.repository }}
          GITHUB_DEFAULT_LABELS: ${{ inputs.github-default-labels }}
          GITHUB_ASSIGNEES: ${{ inputs.github-assignees }}
          CATEGORY_ISSUE_MIN_SEVERITY: ${{ inputs.category-issue-min-severity }}
          
          # Concurrency & Polling
          MAX_CONCURRENT_PENTESTS: ${{ inputs.max-concurrent-pentests }}
          START_STAGGER_SECS: ${{ inputs.start-stagger-secs }}
          MAX_START_RETRIES: ${{ inputs.max-start-retries }}
          START_RETRY_DELAY: ${{ inputs.start-retry-delay }}
          POLL_TIMEOUT_SECS: ${{ inputs.poll-timeout-secs }}
          POLL_TIMEOUT_ACTION: ${{ inputs.poll-timeout-action }}
          GRAPHQL_POLL_INTERVAL_SECS: ${{ inputs.graphql-poll-interval-secs }}

        run: python run_pentest.py

      - name: Extract outcome for output
        id: extract-outcome
        if: always() && (inputs.on-threshold-action == 'fail' || inputs.on-threshold-action == 'both')
        shell: bash
        run: |
          OUTCOME="Unknown"
          
          # Check pentest results
          if [ -f "pentest_results_summary.json" ]; then
            PENTEST_OUTCOME=$(python -c "import json,sys; d=json.load(open('pentest_results_summary.json')); o=[r.get('outcome') for r in d if r.get('outcome')]; print('Critical' if 'Critical' in o else ('Poor' if 'Poor' in o else ('Moderate' if 'Moderate' in o else ('Good' if 'Good' in o else ('Excellent' if 'Excellent' in o else 'Unknown')))))" 2>/dev/null || echo "Unknown")
            echo "Pentest worst outcome: $PENTEST_OUTCOME"
          fi
          
          # Check model scan results
          if [ -f "model_scan_results_summary.json" ]; then
            MODEL_OUTCOME=$(python -c "import json,sys; d=json.load(open('model_scan_results_summary.json')); o=[r.get('outcome') for r in d if r.get('outcome')]; print('Critical' if 'Critical' in o else ('Poor' if 'Poor' in o else ('Moderate' if 'Moderate' in o else ('Good' if 'Good' in o else ('Excellent' if 'Excellent' in o else 'Unknown')))))" 2>/dev/null || echo "Unknown")
            echo "Model scan worst outcome: $MODEL_OUTCOME"
          fi
          
          # Determine overall worst outcome
          if [ -f "pentest_results_summary.json" ] && [ -f "model_scan_results_summary.json" ]; then
            # Both exist - take worse of the two
            if [ "$PENTEST_OUTCOME" = "Critical" ] || [ "$MODEL_OUTCOME" = "Critical" ]; then
              OUTCOME="Critical"
            elif [ "$PENTEST_OUTCOME" = "Poor" ] || [ "$MODEL_OUTCOME" = "Poor" ]; then
              OUTCOME="Poor"
            elif [ "$PENTEST_OUTCOME" = "Moderate" ] || [ "$MODEL_OUTCOME" = "Moderate" ]; then
              OUTCOME="Moderate"
            elif [ "$PENTEST_OUTCOME" = "Good" ] || [ "$MODEL_OUTCOME" = "Good" ]; then
              OUTCOME="Good"
            elif [ "$PENTEST_OUTCOME" = "Excellent" ] || [ "$MODEL_OUTCOME" = "Excellent" ]; then
              OUTCOME="Excellent"
            fi
          elif [ -f "pentest_results_summary.json" ]; then
            OUTCOME="$PENTEST_OUTCOME"
          elif [ -f "model_scan_results_summary.json" ]; then
            OUTCOME="$MODEL_OUTCOME"
          fi
          
          echo "Extracted worst outcome: $OUTCOME"
          echo "outcome=$OUTCOME" >> "$GITHUB_OUTPUT"

      - name: Decide workflow status
        id: decide
        if: always() && (inputs.on-threshold-action == 'fail' || inputs.on-threshold-action == 'both')
        shell: bash
        run: |
          STATUS="${{ steps.scan.outcome }}"
          WORST="${{ steps.extract-outcome.outputs.outcome }}"
          THRESHOLD="${{ inputs.fail-outcome-at-or-above }}"
          WORST="${WORST:-Unknown}"
          
          # If script succeeded, pass
          if [ "$STATUS" = "success" ]; then
            echo "status=success" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          # Script failed - determine if it's a real failure or acceptable
          # Map threshold to severity order: critical=0, poor=1, moderate=2, good=3, excellent=4
          get_severity_index() {
            case "${1,,}" in
              critical) echo 0 ;;
              poor) echo 1 ;;
              moderate) echo 2 ;;
              good) echo 3 ;;
              excellent) echo 4 ;;
              unknown) echo 999 ;;
              *) echo 999 ;;
            esac
          }
          
          WORST_IDX=$(get_severity_index "$WORST")
          THRESHOLD_IDX=$(get_severity_index "$THRESHOLD")
          
          echo "Worst outcome: $WORST (index: $WORST_IDX)"
          echo "Threshold: $THRESHOLD (index: $THRESHOLD_IDX)"
          
          # If worst is at or above threshold (lower index = more severe), fail
          if [ "$WORST_IDX" -le "$THRESHOLD_IDX" ] && [ "$WORST_IDX" -ne 999 ]; then
            echo "status=failure" >> "$GITHUB_OUTPUT"
          else
            echo "status=neutral" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload with timestamp
        if: always()
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          echo "timestamp=$TIMESTAMP" >> "$GITHUB_ENV"

      - name: Upload pentest CSV results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pentest-csv-results-${{ env.timestamp }}
          path: pentest_results_*.csv
          if-no-files-found: ignore
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Upload model scan CSV results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: model-scan-csv-results-${{ env.timestamp }}
          path: model_scan_results_*.csv
          if-no-files-found: ignore
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Upload pentest summary JSON
        if: always() && hashFiles('pentest_results_summary.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: pentest-summary-${{ env.timestamp }}
          path: pentest_results_summary.json
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Upload model scan summary JSON
        if: always() && hashFiles('model_scan_results_summary.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: model-scan-summary-${{ env.timestamp }}
          path: model_scan_results_summary.json
          retention-days: ${{ inputs.artifact-retention-days }}

      - name: Check scan outcome and fail workflow if needed
        if: always() && (inputs.on-threshold-action == 'fail' || inputs.on-threshold-action == 'both')
        run: |
          if [ "${{ steps.decide.outputs.status }}" = "failure" ]; then
            echo "Security scan failed: outcome threshold breached. (or hard failures)"
            exit 1
          elif [ "${{ steps.decide.outputs.status }}" = "neutral" ]; then
            echo "Security scan finished with neutral status."
            exit 0
          else
            echo "Security scan completed successfully."
          fi
