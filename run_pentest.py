from __future__ import annotations

import sys

import config
import auth
import api
from pentest import run_rolling_parallel_with_retry
from summary import finalize_and_exit, finalize_model_scan
from llm_endpoints import select_llm_endpoints
from model_scan import select_models_and_assets, run_model_scans

# Import HuggingFace onboarding if enabled
if config.HUGGINGFACE_ONBOARDING_ENABLED:
    from huggingface_onboarding import onboard_huggingface_models, parse_huggingface_models_from_config


def main() -> int:
    config.print_config_banner()

    jwt = auth.get_jwt_token(config.API_KEY)
    print("[+] JWT token obtained successfully.")

    overall_exit = 0

    # ---------------- LLM Pentest phase (optional) ----------------
    if config.ENABLE_LLM_PENTEST:
        selected_ids, resource_mapping, resource_type_mapping = select_llm_endpoints(jwt)
        if not selected_ids:
            print("✖ No LLM endpoint resources selected. (Pentest phase)")
        else:
            print("\n[2] Listing pentest templates…")
            templates = api.list_pentest_templates(jwt)
            target_name = config.TARGET_TEMPLATE_NAME
            template_id = next(
                (t["llm_pentest_scan_template_id"] for t in templates if t.get("name") == target_name),
                None,
            )

            if template_id is None:
                print(f"✖ Pentest template '{target_name}' was not found.")
                available = ", ".join(t.get("name", "<unnamed>") for t in templates) or "(no templates returned)"
                print(f"    Available templates: {available}")
                print("    Tip: Set TARGET_TEMPLATE_NAME env var to one of the available templates, or create the template in the UI/API.")
            else:
                print(f"[+] Found template '{target_name}' with ID: {template_id}")

                # Determine project_id for dataset resolution
                project_id = None
                if config.PROJECT_IDS:
                    project_id = config.PROJECT_IDS[0]
                    print(f"[i] Using project {project_id} for dataset resolution")
                elif config.PENTEST_DATASET_ENABLED and config.PENTEST_DATASET_NAME:
                    print(f"[!] Warning: PENTEST_DATASET_NAME is set but no PROJECT_IDS configured")
                    print(f"[!] Dataset name resolution requires a project context")
                    print(f"[!] Tip: Set PROJECT_IDS or PROJECT_NAMES in your configuration")

                print(f"\n{'='*80}")
                print(f"STARTING ROLLING PARALLEL PENTESTS FOR {len(selected_ids)} RESOURCES")
                print(f"Max concurrent: {config.MAX_CONCURRENT_PENTESTS} parallel tests")
                print(f"{'='*80}")

                all_results = run_rolling_parallel_with_retry(
                    selected_ids,
                    resource_mapping,
                    resource_type_mapping,
                    template_id,
                    config.MAX_CONCURRENT_PENTESTS,
                    project_id,
                )

                pentest_exit = finalize_and_exit(all_results)
                overall_exit = max(overall_exit, pentest_exit)
    else:
        print("ℹ️ ENABLE_LLM_PENTEST is false; skipping LLM pentest phase.")

    # ---------------- Model scanning phase (optional) ----------------
    if config.ENABLE_MODEL_SCANNING:
        # Step 0: Resolve project names to IDs if needed (for HuggingFace onboarding or inventory)
        # This ensures PROJECT_IDS is populated before onboarding
        from inventory import resolve_config_org_and_projects
        resolved_org_id, resolved_project_ids = resolve_config_org_and_projects(jwt)
        
        # Update config with resolved values
        if resolved_org_id:
            config.ORGANIZATION_ID = resolved_org_id
        if resolved_project_ids:
            config.PROJECT_IDS = resolved_project_ids
        
        # Step 1: Onboard HuggingFace models if enabled
        onboarded_resource_ids = []
        if config.HUGGINGFACE_ONBOARDING_ENABLED:
            print("\n[HuggingFace] Onboarding phase enabled")
            
            # Parse models from config
            models_to_onboard = parse_huggingface_models_from_config()
            
            if models_to_onboard:
                # Determine project ID
                onboarding_project_id = config.HUGGINGFACE_ONBOARDING_PROJECT_ID
                if not onboarding_project_id:
                    if config.PROJECT_IDS:
                        onboarding_project_id = config.PROJECT_IDS[0]
                        print(f"[HuggingFace] Using first configured project: {onboarding_project_id}")
                    else:
                        print("[HuggingFace] ✖ No project ID available for onboarding")
                        print("[HuggingFace]    Set HUGGINGFACE_ONBOARDING_PROJECT_ID or PROJECT_IDS/PROJECT_NAMES")
                        onboarding_project_id = None
                
                if onboarding_project_id:
                    # Onboard the models
                    onboarded_resource_ids = onboard_huggingface_models(
                        jwt=jwt,
                        models=models_to_onboard,
                        project_id=onboarding_project_id
                    )
                    
                    if onboarded_resource_ids:
                        print(f"[HuggingFace] ✓ Onboarded {len(onboarded_resource_ids)} model(s)")
                    else:
                        print(f"[HuggingFace] ✖ Failed to onboard any models")
            else:
                print("[HuggingFace] No models specified in HUGGINGFACE_MODELS_TO_ONBOARD")
        
        # Step 2: Select models from inventory (standard flow)
        # Skip inventory selection if HUGGINGFACE_ONBOARDING_ONLY is enabled
        if config.HUGGINGFACE_ONBOARDING_ONLY and config.HUGGINGFACE_ONBOARDING_ENABLED:
            print("\n[2] Skipping inventory selection (HUGGINGFACE_ONBOARDING_ONLY=true)")
            print("[i] Will scan only onboarded HuggingFace models")
            ms_ids = []
            ms_map = {}
        else:
            print("\n[2] Selecting model/model_asset resources for scanning…")
            ms_ids, ms_map = select_models_and_assets(jwt)
        
        # Step 3: Combine onboarded models with selected models
        if onboarded_resource_ids:
            print(f"[i] Adding {len(onboarded_resource_ids)} onboarded model(s) to scan queue")
            # Add onboarded models to the scan list
            for res_id in onboarded_resource_ids:
                if res_id not in ms_ids:
                    ms_ids.append(res_id)
                    # Try to get the display name from the onboarding response
                    # For now, use a placeholder - the actual name will be fetched during scanning
                    ms_map[res_id] = f"HuggingFace Model (onboarded)"
            print(f"[i] Total models to scan: {len(ms_ids)}")
        
        # Step 4: Run scans
        if not ms_ids:
            print("✖ No model/model_asset resources selected. (Model scanning phase)")
        else:
            ms_results = run_model_scans(jwt, ms_ids, ms_map)

            model_exit = finalize_model_scan(ms_results)  # prints summary + writes model_scan_results_summary.json
            overall_exit = max(overall_exit, model_exit)
    else:
        print("ℹ️ ENABLE_MODEL_SCANNING is false; skipping model scanning phase.")

    return overall_exit


if __name__ == "__main__":
    sys.exit(main())