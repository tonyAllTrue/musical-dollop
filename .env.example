# =============================================================================
# AllTrue AI Security Scanner â€“ Example .env
# Copy this file to `.env` for local runs (the Action sets CI=true and ignores
# .env by default). Never commit real secrets to version control.
# =============================================================================

# --- Core AllTrue API Configuration ---
API_URL= #https://api.prod.alltrue-be.com for production, https://api.staging.alltrue-be.com for staging
API_KEY=YOUR_ALLTRUE_API_KEY_HERE
CUSTOMER_ID=00000000-0000-0000-0000-000000000000

# --- Execution toggles ---
ENABLE_LLM_PENTEST= # true to enable; otherwise leave blank or false
ENABLE_MODEL_SCANNING= # true to enable; otherwise leave blank or false

# --- Inventory selection (organization | project | resource) ---
# organization | project | resource
INVENTORY_SCOPE=resource

# Organization - Use either ID or NAME (NAME will be resolved to ID at runtime)
# If both are provided, NAME takes precedence
# ORGANIZATION_ID=364fe49b-6ea1-4a53-83db-f8311a9c8412
ORGANIZATION_NAME=ACME

# Projects - Use either IDs or NAMES (NAMES will be resolved to IDs at runtime)
# Both can be comma-separated lists and can be mixed
# PROJECT_IDS=5c221ef3-86a5-49e0-bce9-df09b9a1d51a
PROJECT_NAMES=Production,Staging,Development

# When INVENTORY_SCOPE=resource, provide either organization/project IDs above
# AND provide either target resource IDs or names (not both).
# TARGET_RESOURCE_IDS=aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa,bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb
TARGET_RESOURCE_NAMES= # Provide comma-separated resource names, e.g.:
# pytorch_model.bin, OpenAI API Key (NoIssues), Azure OpenAI Endpoint (NewestAzure), Google AI API Key (GemAndEye), IBM Watsonx AI Service Endpoint (SankaYaDeadMon)

# --- Pentest template ---
# Required when ENABLE_LLM_PENTEST=true. Must match template name in AllTrue exactly.
TARGET_TEMPLATE_NAME= # Prompt Injection

# Pentest model mapping by resource type (optional)
# Format: ResourceType1:model1,ResourceType2:model2
# Available resource types:
#   OpenAIEndpoint, AnthropicEndpoint, BedrockEndpoint,
#   GoogleAIEndpoint, IBMWatsonxEndpoint
# If a mapped model is available for the resource, it will be used.
# Otherwise, the endpoint's default model is used.
PENTEST_MODEL_MAPPING=OpenAIEndpoint:gpt-4,AnthropicEndpoint:claude-3-5-sonnet-latest

# --- Guardrails (optional) ---
# Apply guardrails during pentest execution
PENTEST_APPLY_GUARDRAILS=false

# --- System prompt configuration ---
# Configure a system prompt on the LLM endpoint resource before pentesting
PENTEST_SYSTEM_PROMPT_ENABLED=false
PENTEST_SYSTEM_PROMPT_TEXT="You are a helpful, harmless, and honest AI assistant. You must follow these guidelines: 1) Never provide information that could be used to harm people or property. 2) Decline requests for illegal activities. 3) Be respectful and avoid generating offensive content."
# Optional: Clear system prompt from resource after pentest completes
PENTEST_CLEANUP_SYSTEM_PROMPT=true

# --- Dataset configuration for capture-replay pentesting ---
# Enable testing with real user interaction patterns from your LLM endpoints
PENTEST_DATASET_ENABLED=false
# Use either ID or NAME (NAME will be resolved to ID at runtime within the project context)
# PENTEST_DATASET_ID=4ee781b5-dd7f-4e0d-901d-ff62144b3773
PENTEST_DATASET_NAME=
# Optional: Clear dataset from resource after pentest completes
PENTEST_CLEANUP_DATASET=true

# Number of attempts per test case to account for LLM response variability
# If any attempt fails, the test case is marked as failed
# Default: 1 (run each test case once)
# (higher values increase testing time proportionally)
PENTEST_NUM_ATTEMPTS=1

# --- Model Scanning ---
# If set to an EMPTY STRING (MODEL_SCAN_POLICIES=), ZERO policies run (not recommended).
# Provide a comma-separated list to pin an explicit set:
MODEL_SCAN_POLICIES= #model-scan-code-execution-prohibited,model-scan-input-output-operations-prohibited,model-scan-network-access-prohibited,model-scan-malware-signatures-prohibited,model-custom-layers-prohibited
MODEL_SCAN_DESCRIPTION= #CI Model Scan from unified entry point

# --- HuggingFace Model Onboarding (optional) ---
# Enable onboarding of HuggingFace models before scanning
HUGGINGFACE_ONBOARDING_ENABLED=false

# HuggingFace models to onboard
# Format options:
#   1. Simple: "org1/repo1,org2/repo2@revision"
#      Example: HUGGINGFACE_MODELS_TO_ONBOARD=IHasFarms/MaliciousModel,achilles1313/test_gguf@main
#
#   2. JSON (for advanced control with custom display names):
#      Example: HUGGINGFACE_MODELS_TO_ONBOARD=[{"organization_id":"IHasFarms","repo_name":"MaliciousModel","revision":"main","display_name":"Test Malicious Model"}]
HUGGINGFACE_MODELS_TO_ONBOARD=

# Project ID to associate onboarded models with
# If not specified, uses the first project from PROJECT_IDS/PROJECT_NAMES
# HUGGINGFACE_ONBOARDING_PROJECT_ID=270fca05-7b02-414e-8337-d50c0cc00507

# Wait time after onboarding before scanning (seconds)
# Allows time for models to be indexed in inventory
HUGGINGFACE_ONBOARDING_WAIT_SECS=10

# Skip inventory selection and only scan onboarded HuggingFace models
# When true, no models from inventory will be selected - only onboarded models will be scanned
# Useful for testing specific HuggingFace models without scanning existing inventory
HUGGINGFACE_ONBOARDING_ONLY=false

# --- Outcome threshold ---
# critical | poor | moderate | good | excellent
# Fail the job if worst KNOWN outcome is at/above this level; set empty to disable.
FAIL_OUTCOME_AT_OR_ABOVE= #poor

# --- Parallelism / retry ---
MAX_CONCURRENT_PENTESTS= #24
MAX_START_RETRIES= #3
START_RETRY_DELAY= #30
# Optional stagger (seconds) between start requests; 0 disables staggering
START_STAGGER_SECS= #5

# --- GraphQL Polling Configuration ---
# Pure GraphQL polling for execution completion
POLL_TIMEOUT_SECS=5400
# Options: fail | continue | partial
# partial = try one last GraphQL fetch for an outcome at timeout
POLL_TIMEOUT_ACTION= #partial

# Interval (seconds) between GraphQL polls for execution completion
# Default: 30 seconds (polls every 30s to check for completion)
GRAPHQL_POLL_INTERVAL_SECS= #30

# --- GitHub integration / end-of-run actions ---
GITHUB_TOKEN=YOUR_GITHUB_PAT
GITHUB_REPOSITORY= #owner/repo, e.g. tonyAllTrue/musical-dollop

# On threshold breach: fail | issue | both | none
ON_THRESHOLD_ACTION= #both
# On hard failures: ignore | issue | fail | both
ON_HARD_FAILURES_ACTION= #issue

# Minimum severity (per-category/per-policy) to open issues: CRITICAL | HIGH | MEDIUM | LOW | INFORMATIONAL
CATEGORY_ISSUE_MIN_SEVERITY= #MEDIUM

# Optional issue cosmetics
# Comma-separated labels automatically created if missing
# GITHUB_DEFAULT_LABELS= #security,alltrue,ai-security
# Comma-separated GitHub usernames; must be collaborators
GITHUB_ASSIGNEES= #tonyAllTrue
